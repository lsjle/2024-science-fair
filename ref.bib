
@misc{lin2022truthfulqa,
	title={TruthfulQA: Measuring How Models Mimic Human Falsehoods}, 
	author={Stephanie Lin and Jacob Hilton and Owain Evans},
	year={2022},
	eprint={2109.07958},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}
@misc{hendrycks2021measuring,
	title={Measuring Massive Multitask Language Understanding}, 
	author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
	year={2021},
	eprint={2009.03300},
	archivePrefix={arXiv},
	primaryClass={cs.CY}
}
@article{10.1093-mind-LIX.236.433,
	author = {TURING, A. M.},
	title = "{I.—COMPUTING MACHINERY AND INTELLIGENCE}",
	journal = {Mind},
	volume = {LIX},
	number = {236},
	pages = {433-460},
	year = {1950},
	month = {10},
	issn = {0026-4423},
	doi = {10.1093/mind/LIX.236.433},
	url = {https://doi.org/10.1093/mind/LIX.236.433},
	eprint = {https://academic.oup.com/mind/article-pdf/LIX/236/433/30123314/lix-236-433.pdf},
}
@article{4833163d-a6bd-32c4-b1ca-da66259a19e7, ISSN = {00318116, 15730883}, URL = {http://www.jstor.org/stable/4319091}, author = {James H. Moor}, journal = {Philosophical Studies: An International Journal for Philosophy in the Analytic Tradition}, number = {4}, pages = {249—257}, publisher = {Springer}, title = {An Analysis of the Turing Test}, urldate = {2024-01-21}, volume = {30}, year = {1976} }
@article{hendryckstest2021,
	title={Measuring Massive Multitask Language Understanding},
	author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
	journal={Proceedings of the International Conference on Learning Representations (ICLR)},
	year={2021}
}

@article{hendrycks2021ethics,
	title={Aligning AI With Shared Human Values},
	author={Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and Jerry Li and Dawn Song and Jacob Steinhardt},
	journal={Proceedings of the International Conference on Learning Representations (ICLR)},
	year={2021}
}

@article{doi:10.1142/S2705078520300042,
	author = {Ng, Gee Wah and Leung , Wang Chi},
	title = {Strong Artificial Intelligence and Consciousness},
	journal = {Journal of Artificial Intelligence and Consciousness},
	volume = {07},
	number = {01},
	pages = {63-72},
	year = {2020},
	doi = {10.1142/S2705078520300042},
	
	URL = { 
	https://doi.org/10.1142/S2705078520300042
	},
	eprint = { 
	https://doi.org/10.1142/S2705078520300042

	}
	,
	abstract = { In the last 10 years, Artificial Intelligence (AI) has seen successes in fields such as natural language processing, computer vision, speech recognition, robotics and autonomous systems. However, these advances are still considered as Narrow AI, i.e. AI built for very specific or constrained applications. These applications have its usefulness in improving the quality of human life; but it is not good enough to do highly general tasks like what the human can do. The holy grail of AI research is to develop Strong AI or Artificial General Intelligence (AGI), which produces human-level intelligence, i.e. the ability to sense, understand, reason, learn and act in dynamic environments. Strong AI is more than just a composition of Narrow AI technologies. We proposed that it has to be a holistic approach towards understanding and reacting to the operating environment and decision-making process. The Strong AI must be able to demonstrate sentience, emotional intelligence, imagination, effective command of other machines or robots, and self-referring and self-reflecting qualities. This paper will give an overview of current Narrow AI capabilities, present the technical gaps, and highlight future research directions for Strong AI. Could Strong AI become conscious? We provide some discussion pointers. }
}
@misc{lenat2023getting,
	title={Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc}, 
	author={Doug Lenat and Gary Marcus},
	year={2023},
	eprint={2308.04445},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}
@Article{Jobin2019,
	author={Jobin, Anna
	and Ienca, Marcello
	and Vayena, Effy},
	title={The global landscape of AI ethics guidelines},
	journal={Nature Machine Intelligence},
	year={2019},
	month={Sep},
	day={01},
	volume={1},
	number={9},
	pages={389-399},
	abstract={In the past five years, private companies, research institutions and public sector organizations have issued principles and guidelines for ethical artificial intelligence (AI). However, despite an apparent agreement that AI should be `ethical', there is debate about both what constitutes `ethical AI' and which ethical requirements, technical standards and best practices are needed for its realization. To investigate whether a global agreement on these questions is emerging, we mapped and analysed the current corpus of principles and guidelines on ethical AI. Our results reveal a global convergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted, why they are deemed important, what issue, domain or actors they pertain to, and how they should be implemented. Our findings highlight the importance of integrating guideline-development efforts with substantive ethical analysis and adequate implementation strategies.},
	issn={2522-5839},
	doi={10.1038/s42256-019-0088-2},
	url={https://doi.org/10.1038/s42256-019-0088-2}
}


